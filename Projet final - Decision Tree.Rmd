---
title: "Projet final - Decision Tree"
output:
  pdf_document: default
  html_document: default
date: "2023-04-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## R Markdown

```{r}
library(readr)
library(tidyverse)
library(readxl)
library(FactoMineR)
library(factoextra)
library(rpart)
library(rpart.plot)

data <- read_csv("wdbc.data", 
                 col_names = c("ID number",
                               "Diagnosis",
                               "radius_mean",
                               "texture_mean",
                               "perimeter_mean",
                               "area_mean","smoothness_mean",
                               "compactness_mean",
                               "concavity_mean",
                               "concave_points_mean",
                               "symmetry_mean",
                               "fractal_dimension_mean",
                               "radius_SE","texture_SE",
                               "perimeter_SE","area_SE",
                               "smoothness_SE",
                               "compactness_SE",
                               "concavity_SE",
                               "concave_points_SE",
                               "symmetry_SE",
                               "fractal_dimension_SE",
                               "radius_worst",
                               "texture_worst",
                               "perimeter_worst",
                               "area_worst",
                               "smoothness_worst",
                               "compactness_worst",
                               "concavity_worst",
                               "concave_points_worst",
                               "symmetry_worst",
                               "fractal_dimension_worst"))

clean_data <- data %>% 
  select(c(contains("_mean"), Diagnosis)) %>% 
  drop_na()

dt_dataset <- clean_data
```

```{r}
#Création d’un dataset d’apprentissage et d’un dataset de validation
nb_lignes <- floor((nrow(dt_dataset)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
dt_dataset <- dt_dataset[sample(nrow(dt_dataset)), ] #Ajout de numéros de lignes
dt_dataset.train <- dt_dataset[1:nb_lignes, ] #Echantillon d’apprentissage
dt_dataset.test <- dt_dataset[(nb_lignes+1):nrow(dt_dataset), ] #Echantillon de test
```

```{r}
set.seed(123)
#Construction de l’arbre
dataset.Tree <- rpart(Diagnosis ~ ., 
                      data = dt_dataset.train,
                      method = "class", 
                      control = rpart.control(minsplit = 5,
                                              cp=0)
                      )

#Affichage du résultat
rpart.plot(dataset.Tree)

#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(dataset.Tree)
printcp(dataset.Tree)
```

```{r}
#Affichage du cp optimal
print(dataset.Tree$cptable[which.min(dataset.Tree$cptable[,4]),1])
```

```{r}
set.seed(123)
#Elagage de l’arbre avec le cp optimal
dataset.Tree_Opt <- prune(dataset.Tree,
                          cp = dataset.Tree$cptable[which.min(dataset.Tree$cptable[,4]),1])

#Représentation graphique de l’arbre optimal
prp(dataset.Tree_Opt,extra=1)
```

```{r}
#Prédiction du modèle sur les données de test
dataset.test_Predict<-predict(dataset.Tree_Opt,newdata=dt_dataset.test, type= "class")

#Matrice de confusion
mc<-table(dt_dataset.test$Diagnosis, dataset.test_Predict)
print(mc)
```

```{r}
#Erreur de classement
erreur.classement<-1.0-(mc[1,1]+mc[2,2])/sum(mc)
print(erreur.classement)
```

```{r}
#Taux de prédiction
prediction=mc[2,2]/sum(mc[2,])
print(prediction)
```

```{r}
# Calcul pour la classe M
#dt_precision_M <- mc[2,2] / sum(mc[,2])
#dt_recall_M <- mc[2,2] / sum(mc[2,])
#dt_f1_score_M <- 2 * (dt_precision_M * dt_recall_M) / (dt_precision_M + dt_recall_M)

# Calcul pour la classe B
#dt_precision_B <- mc[1,1] / sum(mc[,1])
#dt_recall_B <- mc[1,1] / sum(mc[1,])
#dt_f1_score_B <- 2 * (dt_precision_B * dt_recall_B) / (dt_precision_B + dt_recall_B)

# Affichage des résultats
#print(paste("F1-score pour la classe Malin :", dt_f1_score_M))
#print(paste("F1-score pour la classe Bénin :", dt_f1_score_B))
```

```{r}
#Calcul des mesures pour chaque classe
dt_precision <- diag(mc) / colSums(mc)
dt_recall <- diag(mc) / rowSums(mc)
dt_f1_score <- 2 * dt_precision * dt_recall / (dt_precision + dt_recall)
dt_accuracy <- sum(diag(mc)) / sum(mc)

#Création d'un tableau avec les mesures pour chaque classe
results <- data.frame(Class = rownames(mc),
                      Precision = dt_precision,
                      Recall = dt_recall,
                      F1_score = dt_f1_score)
#Ajout de l'accuracy
results <- rbind(results, c("Overall", "-", "-", "-", dt_accuracy)) 

#Affichage des résultats
print(results)
```
