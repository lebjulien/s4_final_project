---
title: "Projet final Test 2"
output: html_document
date: "2023-04-24"
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question n°2

### 1 - Analyse descriptive du jeu de donnée par clustering

Pour réaliser cette analyse descriptive, nous allons réaliser une analyse par clustering en utilisant la méthode des [**k-means**]{.underline}.

Dans un premier temps, il est alors nécessaire de charger et de nettoyer le jeu de données en renommant les variables et en éliminant les donées manquantes.

```{r}
library(readr)
library(tidyverse)
library(readxl)
library(FactoMineR)
library(factoextra)
library(arsenal)

data <- read_csv("wdbc.data", 
                 col_names = c("ID number",
                               "Diagnosis",
                               "radius_mean",
                               "texture_mean",
                               "perimeter_mean",
                               "area_mean","smoothness_mean",
                               "compactness_mean",
                               "concavity_mean",
                               "concave_points_mean",
                               "symmetry_mean",
                               "fractal_dimension_mean",
                               "radius_SE","texture_SE",
                               "perimeter_SE","area_SE",
                               "smoothness_SE",
                               "compactness_SE",
                               "concavity_SE",
                               "concave_points_SE",
                               "symmetry_SE",
                               "fractal_dimension_SE",
                               "radius_worst",
                               "texture_worst",
                               "perimeter_worst",
                               "area_worst",
                               "smoothness_worst",
                               "compactness_worst",
                               "concavity_worst",
                               "concave_points_worst",
                               "symmetry_worst",
                               "fractal_dimension_worst"))

clean_data <- data %>% 
  select(c(contains("_mean"), Diagnosis)) %>% 
  drop_na()

km_dataset <- data %>% 
  drop_na()
```

```{r}
set.seed(123)
```

```{r}
# Cluster Analysis - kmeans
kmeans_basic <- kmeans(km_dataset[,3:12], centers = 2)
kmeans_basic_table <- data.frame(kmeans_basic$size, kmeans_basic$centers)
kmeans_basic_df <- data.frame(Cluster = kmeans_basic$cluster, km_dataset)

# head of df
head(kmeans_basic_df)
```

```{r}
# Example ggplot
ggplot(data = kmeans_basic_df, aes(y = Cluster)) +
  geom_bar(aes(fill = Diagnosis)) +
  ggtitle("Count of Clusters by Diagnosis") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Fancy K-Means
fviz_nbclust(scale(km_dataset[,3:12]), kmeans, nstart=100, method = "wss") + 
  geom_vline(xintercept = 2, linetype = 1)
```

```{r}
# Fancy kmeans
kmeans_fancy <- kmeans(scale(km_dataset[,3:12]), 2, nstart = 100)
# plot the clusters
fviz_cluster(kmeans_fancy, data = scale(km_dataset[,3:12]), geom = c("point"),ellipse.type = "euclid")
```

```{r}
outCtl <- tableby(Cluster ~ Diagnosis + radius_mean + texture_mean + perimeter_mean + area_mean + smoothness_mean + compactness_mean + concavity_mean + concave_points_mean + symmetry_mean + fractal_dimension_mean, data=kmeans_basic_df,
                  control=tableby.control(total=TRUE, cat.simplify=TRUE,
                  cat.stats=c("Nmiss","countpct"),digits=1))
summary(outCtl, text=TRUE)
```

## Question 3

### 1 - Méthode par Arbre de décision

Tout d'abord il est nécessaire de réaliser un chargement des données dans un dataset distinct.

```{r}
library(tidyverse)
library(FactoMineR)
library(factoextra)
library(rpart)
library(rpart.plot)

dt_dataset <- clean_data
```

Création d'un dataset d'apprentissage et d'un dataset de validation

```{r}
nb_lignes <- floor((nrow(dt_dataset)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
dt_dataset <- dt_dataset[sample(nrow(dt_dataset)), ] #Ajout de numéros de lignes
dt_dataset.train <- dt_dataset[1:nb_lignes, ] #Echantillon d’apprentissage
dt_dataset.test <- dt_dataset[(nb_lignes+1):nrow(dt_dataset), ] #Echantillon de test
```

```{r}
set.seed(123)
#Construction de l’arbre
dataset.Tree <- rpart(Diagnosis ~ ., 
                      data = dt_dataset.train,
                      method = "class", 
                      control = rpart.control(minsplit = 5,
                                              cp=0)
                      )

#Affichage du résultat
rpart.plot(dataset.Tree)

#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(dataset.Tree)
printcp(dataset.Tree)
```

Affichage du cp optimal

```{r}
print(dataset.Tree$cptable[which.min(dataset.Tree$cptable[,4]),1])
```

```{r}
set.seed(123)
#Elagage de l’arbre avec le cp optimal
dataset.Tree_Opt <- prune(dataset.Tree,
                          cp = dataset.Tree$cptable[which.min(dataset.Tree$cptable[,4]),1])

#Représentation graphique de l’arbre optimal
prp(dataset.Tree_Opt,extra=1)
```

```{r}
#Prédiction du modèle sur les données de test
dataset.test_Predict<-predict(dataset.Tree_Opt,newdata=dt_dataset.test, type= "class")

#Matrice de confusion
mc<-table(dt_dataset.test$Diagnosis, dataset.test_Predict)
print(mc)
```

```{r}
#Erreur de classement
erreur.classement<-1.0-(mc[1,1]+mc[2,2])/sum(mc)
print(erreur.classement)
```

```{r}
#Taux de prédiction
prediction=mc[2,2]/sum(mc[2,])
print(prediction)
```

```{r}
# Calcul pour la classe M
#dt_precision_M <- mc[2,2] / sum(mc[,2])
#dt_recall_M <- mc[2,2] / sum(mc[2,])
#dt_f1_score_M <- 2 * (dt_precision_M * dt_recall_M) / (dt_precision_M + dt_recall_M)

# Calcul pour la classe B
#dt_precision_B <- mc[1,1] / sum(mc[,1])
#dt_recall_B <- mc[1,1] / sum(mc[1,])
#dt_f1_score_B <- 2 * (dt_precision_B * dt_recall_B) / (dt_precision_B + dt_recall_B)

# Affichage des résultats
#print(paste("F1-score pour la classe Malin :", dt_f1_score_M))
#print(paste("F1-score pour la classe Bénin :", dt_f1_score_B))
```

```{r}
#Calcul des mesures pour chaque classe
dt_precision <- diag(mc) / colSums(mc)
dt_recall <- diag(mc) / rowSums(mc)
dt_f1_score <- 2 * dt_precision * dt_recall / (dt_precision + dt_recall)
dt_accuracy <- sum(diag(mc)) / sum(mc)

#Création d'un tableau avec les mesures pour chaque classe
results <- data.frame(Class = rownames(mc),
                      Precision = dt_precision,
                      Recall = dt_recall,
                      F1_score = dt_f1_score)

#Affichage des résultats
print(results)
print(dt_accuracy)
```

### 2 - Méthode par Forets aléatoires

```{r}
library(readr)
library(randomForest)
library(plotly)

rf_dataset <- clean_data

rf_dataset$Diagnosis <- factor(rf_dataset$Diagnosis)
```

```{r}
# Diviser les données en ensembles d'apprentissage et de test
set.seed(123) # pour la reproductibilité des résultats

train_index <- sample(nrow(rf_dataset), 0.7 * nrow(rf_dataset))
train_data <- rf_dataset[train_index, ]
test_data <- rf_dataset[-train_index, ]
```

```{r}
# Entraîner le modèle de forêt aléatoire
rf_model <- randomForest(Diagnosis ~ ., data = train_data, ntree = 100, mtry = 2, na.action = na.omit)

# Afficher les résultats du modèle
print(rf_model)
```

```{r}
# Calculer l'importance des variables
var_importance <- importance(rf_model)

# Afficher les variables les plus importantes
print(var_importance)
```

```{r}
# Évaluer la performance du modèle sur les données de test
rf_predictions <- predict(rf_model, test_data)
confusion_matrix <- table(rf_predictions, test_data$Diagnosis)
accuracy <- sum(diag(confusion_matrix))/sum(confusion_matrix)

# Afficher la matrice de confusion et la précision
print(confusion_matrix)
```

```{r}
# Calcul pour la classe M
precision_M <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
recall_M <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
f1_score_M <- 2 * (precision_M * recall_M) / (precision_M + recall_M)

# Calcul pour la classe B
precision_B <- confusion_matrix[1,1] / sum(confusion_matrix[,1])
recall_B <- confusion_matrix[1,1] / sum(confusion_matrix[1,])
f1_score_B <- 2 * (precision_B * recall_B) / (precision_B + recall_B)

# Affichage des résultats
print(paste("F1-score pour la classe Malin :", f1_score_M))
print(paste("F1-score pour la classe Bénin :", f1_score_B))
```


### 3 - Méthode par Ensemble Learning

```{r}
library(tidyverse)
library(mlbench)
library(caret)
library(caretEnsemble)

el_dataset <- clean_data
```

```{r}
# Example of Boosting Algorithms
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"

# C5.0
set.seed(seed)
fit.c50 <- train(Diagnosis~., data=clean_data, method="C5.0", metric=metric, trControl=control)

# Stochastic Gradient Boosting
set.seed(seed)
fit.gbm <- train(Diagnosis~., data=clean_data, method="gbm", metric=metric, trControl=control, verbose=FALSE)

# summarize results
boosting_results <- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
summary(boosting_results)
dotplot(boosting_results)
```

```{r}
# Example of Bagging algorithms
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"

# Bagged CART
set.seed(seed)
fit.treebag <- train(Diagnosis~., data=clean_data, method="treebag", metric=metric, trControl=control)

# Random Forest
set.seed(seed)
fit.rf <- train(Diagnosis~., data=clean_data, method="rf", metric=metric, trControl=control)

# summarize results
bagging_results <- resamples(list(treebag=fit.treebag, rf=fit.rf))
summary(bagging_results)
dotplot(bagging_results)
```

```{r}
# Example of Stacking algorithms
# create submodels
control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')
set.seed(seed)
models <- caretList(Diagnosis~., data=clean_data, trControl=control, methodList=algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
```

```{r}
# stack using glm
stackControl <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
set.seed(seed)
stack.glm <- caretStack(models, method="glm", metric="Accuracy", trControl=stackControl)
print(stack.glm)
```

```{r}
# stack using random forest
set.seed(seed)
stack.rf <- caretStack(models, method="rf", metric="Accuracy", trControl=stackControl)
print(stack.rf)
```

